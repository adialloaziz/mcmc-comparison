{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC CALIBRATION TECHNICS IN CONTEXT OF  INFECTIOUS DISEASE MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install multiprocess\n",
    "# %pip install --upgrade --force-reinstall multiprocess\n",
    "\n",
    "#Compatible with latest jax version  \n",
    "# %pip install summerepi2==1.3.6\n",
    "# %pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is required for pymc parallel evaluation in notebooks\n",
    "\n",
    "import multiprocess as mp\n",
    "import platform\n",
    "\n",
    "if platform.system() != \"Windows\":\n",
    "    \n",
    "    mp.set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Calibrate as cal #Runing the calibration process and gathering results\n",
    "from calibs_utilities import get_all_priors, get_targets, load_data\n",
    "from models.models import model1 #All the models we design for the test\n",
    "from Calibrate import plot_comparison_Bars\n",
    "\n",
    "# Combining tagets and prior with our summer2 model in a BayesianCompartmentalModel (bcm_model_1_model_1_model_1_model_1_model_1_model_1_model_1)\n",
    "from estival.model import BayesianCompartmentalModel\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "# We use estivals parallel tools to run the model evaluations\n",
    "from estival.utils.parallel import map_parallel\n",
    "\n",
    "# import numpyro\n",
    "# from numpyro import distributions as dist\n",
    "from numpyro import infer\n",
    "import arviz as az\n",
    "import pickle\n",
    "# import jax\n",
    "# from jax import numpy as jnp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Data\n",
    "If data are needed to define a target, we just need to import it from our file data which we will design correctly.\n",
    "In this example we import data from a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An example of data for the calibration \n",
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "\n",
    "output_labels = {\"index\": \"time\", \"value\": \"number infectious\"}\n",
    "\n",
    "targets_yml = './data/target_yml.yml'\n",
    "targets = load_data(targets_yml)\n",
    "targets_data = targets['active_cases']\n",
    "\n",
    "# targets_data.plot(kind=\"scatter\",labels=output_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Names of parameters and their ranges\n",
    "params = {\n",
    "    \"contact_rate\": (0.0,1.0),\n",
    "    \"recovery_rate\": (0.0,1.0)\n",
    "\n",
    "}\n",
    "targets = get_targets(targets_yml)\n",
    "priors = get_all_priors(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and Configuration\n",
    "\n",
    "A mechanistic model (ODE-Based) model discribing Infectious Disease transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"contact_rate\": 0.2,\n",
    "    \"recovery_rate\": 0.1,\n",
    "    #\"active_cases_dispersion\": 0.5,\n",
    "}\n",
    "\n",
    "model_1.run(parameters)\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"modelled\": model_1.get_outputs_df()[\"infectious\"],\n",
    "        \"observed\": targets_data,\n",
    "    }\n",
    ").plot(kind=\"scatter\", labels=output_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining  a Bayesian Compartmental Model\n",
    "\n",
    "bcm_model_1 = BayesianCompartmentalModel(model_1, parameters, priors, targets)\n",
    "T = bcm_model_1.targets[\"active_cases\"]\n",
    "T.stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##____Uniform Initialisation_________\n",
    "init_vals = []\n",
    "for c in range(4):\n",
    "    init_vals.append({param: np.random.uniform(0.0,1.0) for param in parameters.keys()})\n",
    " \n",
    "init_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "D = 2 # Dimension of the parameter's space\n",
    "samplers = [infer.NUTS]*2 + [pm.DEMetropolisZ]*2 + [pm.DEMetropolis]*2 + [pm.Metropolis]*4\n",
    "Draws = [2000]*2 + [4000]*6+ [8000]*2\n",
    "Tunes = [100,1000]*5\n",
    "chains = 2*D\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for sampler, draws, tune in zip (samplers, Draws, Tunes):\n",
    "    \n",
    "    results = cal.multirun(sampler = sampler, \n",
    "            draws = draws,\n",
    "            tune = tune,\n",
    "            bcm_model = bcm_model_1,\n",
    "            n_iterations = 1,\n",
    "            n_jobs = 1,\n",
    "            initial_params = init_vals\n",
    "\n",
    "    )\n",
    "            \n",
    "    df = pd.concat([df,results])\n",
    "\n",
    "\n",
    "results_df = df\n",
    "\n",
    "results_df = results_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.style.set_caption(\"MCMC COMPARISON\") \n",
    "\n",
    "#Storing results on a pickle file\n",
    "with open('./Results/Model_1/Experiment_1/Simple_run_results.pkl', 'wb') as fp:\n",
    "    pickle.dump(results_df, fp)\n",
    "\n",
    "\n",
    "# #Loading a pickle file\n",
    "# with open('./Results/Model_1/Experiment_1/Simple_run_results.pkl', 'rb') as fp:\n",
    "#     res = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_Bars(results_df=results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = infer.NUTS\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 2000,\n",
    "    tune = 1000, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 4,\n",
    "    initial_params = init_vals\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.DEMetropolis\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 4000,\n",
    "    tune = 1000, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 4,\n",
    "    initial_params = init_vals\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.DEMetropolisZ\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 4000,\n",
    "    tune = 1000, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 4,\n",
    "    initial_params = init_vals\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.Metropolis\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 8000,\n",
    "    tune = 1000, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 4,\n",
    "    initial_params = init_vals\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the results for later analysis\n",
    "\n",
    "with open('./Results/Model_1/Experiment_1/Simple_run_results.pkl', 'wb') as fp:\n",
    "    pickle.dump(all_results, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results[results[\"Rhat_max\"] > 1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using arviz for trace visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idata, Run, draws, tune in zip(results_df.Trace, results_df.Run, results_df.Draws, results_df.Tune):\n",
    "    subset = idata.sel(draw=slice(0, None), groups=\"posterior\")\n",
    "    print(\"Run = \",Run)\n",
    "    az.plot_trace(subset, figsize=(16,3.2*len(subset.posterior)),compact=False)#, lines=[(\"m\", {}, mtrue), (\"c\", {}, ctrue)]);\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idata[\"sample_stats\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival.sampling.tools import likelihood_extras_for_idata\n",
    "from estival.sampling import tools as esamptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the likelihood function for each sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival.model.base import ResultsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res : List[ResultsData]\n",
    "targets_datas = pd.DataFrame(targets_data)\n",
    "\n",
    "targets_datas.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=0 \n",
    "#pd.options.plotting.backend = \"matplotlib\"\n",
    "#map_res = np.zeros(8, dtype=ResultsData) #To specify the type of the elements in the list, default is tuple\n",
    "map_res : List[ResultsData]\n",
    "map_params = []\n",
    "for idata, sampler ,run in zip(results_df.Trace, results_df.Sampler, results_df.Run):\n",
    "    if (sampler == \"metropolis\"): #Because pm.metropolis is not compatible directly with the likelihood function from est.samp.tools\n",
    "        # print(sampler)\n",
    "       likelihood_df = esamptools.likelihood_extras_for_samples(idata.posterior, bcm_model_1)\n",
    "\n",
    "    else :\n",
    "        likelihood_df = likelihood_extras_for_idata(idata, bcm_model_1)\n",
    "    ldf_sorted = likelihood_df.sort_values(by=\"logposterior\",ascending=False)\n",
    "    map_parameter = idata.posterior.to_dataframe().loc[ldf_sorted.index[0]].to_dict()\n",
    "    print(idata.posterior.to_dataframe().loc[ldf_sorted.index[0]])\n",
    "\n",
    "    map_params.append(map_parameter)\n",
    "    map_res.append(bcm_model_1.run(map_parameter))\n",
    "    # res = bcm_model_1.run(map_parameter)\n",
    "    # output = res.derived_outputs[\"active_cases\"]\n",
    "\n",
    "    # ax = pd.DataFrame(\n",
    "    #     {\n",
    "    #         f\"{run}\": output,\n",
    "    #         \"Observed\" : targets_datas,\n",
    "    #     }\n",
    "    # ).plot(kind=\"scatter\", x=targets_datas.index, y=targets_datas.values, labels=output_labels)\n",
    "    # plt.show()\n",
    "    #map_res[i] = bcm_model_1.run(map_parameter)\n",
    "    #i+=1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in zip (map_res):\n",
    "    res\n",
    "\n",
    "res[0].derived_outputs[\"active_cases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for sampler, res, draws in zip(results_df.Sampler, map_res, results_df.Draws):\n",
    "    res = res[0]\n",
    "    ax = pd.DataFrame(\n",
    "        {\n",
    "            f\"{sampler}, draws = {draws}\": res.derived_outputs[\"active_cases\"],\n",
    "            \"Observed\" : targets_data,\n",
    "        }\n",
    "    ).plot(kind=\"scatter\", labels=output_labels)\n",
    "   \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#    comb_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "#    comb_df.plot(kind=\"scatter\", labels=output_labels)\n",
    "# comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.run(map_params)\n",
    "\"\"\"\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"DEMetropolisZ\": map_res[0].derived_outputs[\"active_cases\"],\n",
    "        \"DEMetropolis\": map_res[1].derived_outputs[\"active_cases\"],\n",
    "        \"Metropolis\": map_res[2].derived_outputs[\"active_cases\"],\n",
    "        f\"Metropolis, draws\": map_res[3].derived_outputs[\"active_cases\"],\n",
    "\n",
    "\n",
    "        \"observed\": targets_data,\n",
    "    }\n",
    ").plot(kind=\"scatter\", labels=output_labels)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the arviz extract method to obtain some samples, then convert to a DataFrame\n",
    "sample_idata = az.extract(idata, num_samples=4000)\n",
    "samples_df = sample_idata.to_dataframe().drop(columns=[\"chain\",\"draw\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function captures our bcm from the main namespace to pass into map_parallel\n",
    "# Using this idiom in closures/factory functions is typical\n",
    "def run_sample(idx_sample):\n",
    "    idx, params = idx_sample\n",
    "    return idx, bcm_model_1.run(params)\n",
    "\n",
    "# Run the samples through our BCM using the above function\n",
    "# map_parallel takes a function and an iterable as input\n",
    "\n",
    "# We use 4 workers here, default is cpu_count/2 (assumes hyperthreading)\n",
    "sample_res = map_parallel(run_sample, samples_df.iterrows(), n_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use xarray for this step; aside from computing things very quickly, it's useful\n",
    "# to persist the run results to netcdf/zarr etc\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataArray out of our results, then assign coords for indexing\n",
    "xres = xr.DataArray(np.stack([r.derived_outputs for idx, r in sample_res]), \n",
    "                    dims=[\"sample\",\"time\",\"variable\"])\n",
    "xres = xres.assign_coords(sample=sample_idata.coords[\"sample\"], \n",
    "                          time=map_res[-1].derived_outputs.index, variable=map_res[-1].derived_outputs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some quantiles to calculate\n",
    "quantiles = (0.25,0.5,0.75,0.80,0.95)\n",
    "\n",
    "# Generate a new DataArray containing the quantiles\n",
    "xquantiles = xres.quantile(quantiles,dim=[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract these values to a pandas DataFrame for ease of plotting\n",
    "\n",
    "uncertainty_df = xquantiles.to_dataframe(name=\"value\").reset_index().set_index(\"time\").pivot(columns=(\"variable\",\"quantile\"))[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"active_cases\"\n",
    "\n",
    "fig = uncertainty_df[variable].plot(title=variable,alpha=0.7)\n",
    "pd.Series(map_res[-1].derived_outputs[variable]).plot(style='--')\n",
    "bcm_model_1.targets[variable].data.plot(style='.',color=\"black\", ms=5, alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the posterior likelihood landscape analysis using ELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pflacco\n",
    "from pflacco.classical_ela_features import *\n",
    "from pflacco.local_optima_network_features import compute_local_optima_network, calculate_lon_features\n",
    "#__To___create_a_initial____sample\n",
    "from pflacco.sampling import create_initial_sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
