{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC CALIBRATION TECHNICS IN CONTEXT OF  INFECTIOUS DISEASE MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install multiprocess\n",
    "# %pip install --upgrade --force-reinstall multiprocess\n",
    "\n",
    "#Compatible with latest jax version  \n",
    "# %pip install summerepi2==1.3.6\n",
    "# %pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess as mp\n",
    "import platform\n",
    "\n",
    "# This is required for pymc parallel evaluation in notebooks \n",
    "# But has to be change while using a python script \n",
    "# Use this following instruction instead\n",
    "# if __name__ == \"__main__\":\n",
    "#     if platform.system() != \"Windows\":\n",
    "#         mp.set_start_method('spawn')\n",
    "    \n",
    "    # rest of your code body here inside the if __name__\n",
    "if platform.system() != \"Windows\":\n",
    "    \n",
    "    mp.set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Calibrate as cal #Runing the calibration process and gathering results\n",
    "from calibs_utilities import get_all_priors, get_targets, load_data\n",
    "from models.models import model1, model2, bcm_seir_age_strat, bcm_sir #All the models we design for the test\n",
    "from Calibrate import plot_comparison_bars\n",
    "\n",
    "# Combining tagets and prior with our summer2 model in a BayesianCompartmentalModel (bcm_model_1)\n",
    "from estival.model import BayesianCompartmentalModel\n",
    "from estival.sampling.tools import likelihood_extras_for_idata\n",
    "from estival.sampling.tools import likelihood_extras_for_samples\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "# We use estivals parallel tools to run the model evaluations\n",
    "from estival.utils.parallel import map_parallel\n",
    "\n",
    "import numpyro\n",
    "from numpyro import distributions as dist\n",
    "from numpyro import infer\n",
    "import arviz as az\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from plotly import graph_objects as go\n",
    "# import jax\n",
    "from jax import numpy as jnp\n",
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "# pd.options.plotting.backend = \"matplotlib\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 1: The basic SIR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and Configuration\n",
    "\n",
    "A mechanistic model (ODE-Based) model discribing Infectious Disease transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model1() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining  a Bayesian Compartmental Model\n",
    "#Targets and priors are already defined with the data \n",
    "#See models.py for the costumization\n",
    "bcm_model_1 = bcm_sir()\n",
    "# bcm_model_1 = BayesianCompartmentalModel(model_1, parameters, priors, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "output_labels = {\"index\": \"time\", \"value\": \"number infectious\"}\n",
    "\n",
    "model_1.run(bcm_model_1.parameters)\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"modelled\": model_1.get_outputs_df()[\"I\"],\n",
    "        \"observed\": bcm_model_1.targets[\"active_cases\"].data,\n",
    "    }\n",
    ")\n",
    "df.plot(kind=\"scatter\", labels=output_labels) #,figsize=(3,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##____Uniform Initialisation_________\n",
    "def init_uniform(num_chains, parameters):\n",
    "    init_vals = []\n",
    "    for c in range(num_chains):\n",
    "        init_vals.append({param: np.random.uniform(0.0,1.0) for param in parameters.keys()})\n",
    "    \n",
    "    return init_vals\n",
    "\n",
    "\n",
    "init_vals_nuts = {param: jnp.array(np.random.uniform(0.0,1.0, 4)) for param in bcm_model_1.parameters.keys()}\n",
    "\n",
    "init_vals_4 = init_uniform(4,bcm_model_1.parameters)\n",
    "init_vals_6 = init_uniform(6,bcm_model_1.parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Numpyro model using our likelihood from the BaysianCompartmentalModel\n",
    "def nmodel():\n",
    "    sampled = {k:numpyro.sample(k, dist.Uniform(0.0,1.0)) for k in bcm_model_1.parameters}\n",
    "    ll = numpyro.factor(\"ll\", bcm_model_1.loglikelihood(**sampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "D = 2 # Dimension of the parameter's space\n",
    "samplers =  [infer.NUTS] + [pm.sample_smc] + [pm.Metropolis] + [pm.DEMetropolisZ] + [pm.DEMetropolis]*2\n",
    "Draws = [2000] + [2000] + [10000] + [8000]*3\n",
    "# Tunes = [0] + [100, 1000]*5\n",
    "Init = [init_vals_nuts] + [init_vals_4]*4 + [init_vals_6]\n",
    "Chains = [4]*5 + [6]\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for sampler, draws, chains, init in zip(samplers, Draws, Chains, Init):\n",
    "    # if sampler.__name__ == \"NUTS\":\n",
    "    #     init = init_vals_nuts\n",
    "    # else:\n",
    "    #     init = init_vals_4\n",
    "    results = cal.Single_analysis(sampler = sampler, \n",
    "            draws = draws,\n",
    "            chains=chains,\n",
    "            cores = chains,\n",
    "            tune = 1000,\n",
    "            bcm_model = bcm_model_1,\n",
    "            # n_iterations = 1,\n",
    "            nmodel=nmodel,\n",
    "            # n_jobs = 1,\n",
    "            initial_params = init\n",
    "\n",
    "    )\n",
    "            \n",
    "    results_df = pd.concat([results_df,results])\n",
    "\n",
    "\n",
    "\n",
    "results_df = results_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df\n",
    "results_df.style.set_caption(\"MCMC COMPARISON\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Storing results on a pickle file\n",
    "with open('./Results/Model_1/Simple_run_results_3.pkl', 'wb') as fp:\n",
    "    pickle.dump(results_df, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.sample_smc\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    tune = 1000,\n",
    "    chains=4,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.DEMetropolisZ\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    chains=4,\n",
    "    cores=4,\n",
    "    tune = 1000, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.Metropolis\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    tune = 1000, \n",
    "    chains=4,\n",
    "    cores=4,\n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = infer.NUTS\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    tune = 1000,\n",
    "    chains=4,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    nmodel=nmodel,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.DEMetropolis\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 1000,\n",
    "    tune = 1000,\n",
    "    chains=6,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"DEMetropolis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the results for later analysis\n",
    "\n",
    "with open('./Results/Model_1/Multi_run_results_without_init_1.pkl', 'wb') as fp:\n",
    "    pickle.dump(all_results, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing the 100 results\n",
    "\n",
    "We call the function group_summary from the calibrate modules. This will help to figure out the average performance\n",
    "of sampler over 100 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a pickle file\n",
    "with open('./Results/Model_1/Multi_run_results_3.pkl', 'rb') as fp:\n",
    "    multi_res = pickle.load(fp) #It's a dict\n",
    "df = pd.concat(multi_res) #converting to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here best results refers to the run with the min 'Max_rhat' for each sampler over the  runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = pd.DataFrame()\n",
    "for sampler in multi_res.keys():\n",
    "    temp = multi_res[sampler].round(3)\n",
    "    temp\n",
    "    best_rhat = temp.loc[[temp[\"Rhat_max\"].idxmin()]]\n",
    "    best_results = pd.concat([best_results,best_rhat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = best_results.reset_index(drop=True)\n",
    "#Computing the Relative ESS\n",
    "best_results[\"Rel_Ess\"] = best_results['Min_Ess'].astype(float)/(best_results[\"Draws\"].astype(float)*best_results['Chains'].astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_mean, prcnt_succ = cal.group_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_mean.round(2).to_latex(column_format=\"|c|c|c|c|c|c|c|c|c|c|c|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcnt_succ = prcnt_succ.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcnt_succ#.to_latex(column_format='|c|c|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using arviz for trace visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idata, sampler in zip(best_results.Trace, best_results.Sampler):\n",
    "    print(sampler)\n",
    "    az.plot_rank(idata,figsize=(9,4))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Ploting Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_comparison_Bars(results_df=res)\n",
    "best_results[\"Run\"] = best_results.Sampler + \"\\nDraws=\" + best_results.Draws.astype(str) + \"\\nTune=\" + best_results.Tune.astype(str) +\"\\nChains=\" + best_results.Chains.astype(str)\n",
    "plot_comparison_bars(best_results.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting test\n",
    "\n",
    "Here we test if the model is well fitted to the data, we will use the results from the single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDATA = best_results[\"Trace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res = dict()\n",
    "for idata, sampler in zip(IDATA,best_results[\"Sampler\"]):\n",
    "    map_res[sampler] = cal.fitting_test(idata, bcm_model_1, model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "\n",
    "NUTS = map_res[\"NUTS\"][\"I\"]\n",
    "SMC = map_res[\"sample_smc\"][\"I\"]\n",
    "DEM = map_res[\"DEMetropolis\"][\"I\"]\n",
    "MH = map_res[\"Metropolis\"][\"I\"]\n",
    "DEMZ = map_res[\"DEMetropolisZ\"][\"I\"]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {   \n",
    "        \"MH\": MH,\n",
    "        \"NUTS\": NUTS,\n",
    "        \"SMC\": SMC,\n",
    "        \"DEM\": DEM,\n",
    "        \"DEMZ\": DEMZ,\n",
    "        \"observed\": bcm_model_1.targets[\"active_cases\"].data,\n",
    "    }\n",
    ")\n",
    "df.plot(kind=\"scatter\", labels=output_labels, title=\"Model fitting\")#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function captures our bcm from the main namespace to pass into map_parallel\n",
    "# Using this idiom in closures/factory functions is typical\n",
    "def run_sample(idx_sample):\n",
    "    idx, params = idx_sample\n",
    "    return idx, bcm_model_1.run(params)\n",
    "\n",
    "# Run the samples through our BCM using the above function\n",
    "# map_parallel takes a function and an iterable as input\n",
    "\n",
    "# We use 4 workers here, default is cpu_count/2 (assumes hyperthreading)\n",
    "sample_res = dict()\n",
    "for idata,sampler in zip(IDATA,best_results[\"Sampler\"]):\n",
    "    sample_idata = az.extract(idata, num_samples=4000)\n",
    "    samples_df = sample_idata.to_dataframe().drop(columns=[\"chain\",\"draw\"])\n",
    "    sample_res[sampler] = map_parallel(run_sample, samples_df.iterrows(), n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use xarray for this step; aside from computing things very quickly, it's useful\n",
    "# to persist the run results to netcdf/zarr etc\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataArray out of our results, then assign coords for indexing\n",
    "xres = xr.DataArray(np.stack([r.derived_outputs for idx, r in sample_res[\"NUTS\"]]), \n",
    "                    dims=[\"sample\",\"time\",\"variable\"])\n",
    "xres = xres.assign_coords(sample=sample_idata.coords[\"sample\"], \n",
    "                          time=map_res[\"NUTS\"].index, variable=pd.DataFrame(map_res[\"NUTS\"][\"I\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some quantiles to calculate\n",
    "quantiles = (0.5,0.75,0.95)\n",
    "\n",
    "# Generate a new DataArray containing the quantiles\n",
    "xquantiles = xres.quantile(quantiles,dim=[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract these values to a pandas DataFrame for ease of plotting\n",
    "\n",
    "uncertainty_df = xquantiles.to_dataframe(name=\"value\").reset_index().set_index(\"time\").pivot(columns=(\"variable\",\"quantile\"))[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"active_cases\"\n",
    "pd.options.plotting.backend = \"matplotlib\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "\n",
    "fig = uncertainty_df[\"I\"].plot.area(title=variable,alpha=0.7)\n",
    "pd.Series(map_res[\"NUTS\"][\"I\"]).plot(label = \"modelled\",style='--')\n",
    "bcm_model_1.targets[variable].data.plot(label = \"observed\",style='.',color=\"black\", ms=5, alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 2: The SEIR age-stratified model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for fitting\n",
    "Here we will define a target for each age category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = pd.read_csv(\"./data/new_cases_England_2020.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df.date)\n",
    "df.set_index([\"age\",\"date\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases = df.groupby(\"date\").sum()\n",
    "#Rolling by 14 days to discard fluctuations\n",
    "total_cases = total_cases.rolling(14).mean().iloc[14:]\n",
    "# D = total_cases[\"Jun 2020\":\"Nov 2020\"].iloc[::5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\"compartments\": (\"S\", \"E\",\"I\",\"R\"), # \"Ip\",\"Ic\", \"Is\", \"R\"),\n",
    "        \"population\": 56490045, #England population size 2021\n",
    "        \"start_time\": datetime(2020, 6, 1),\n",
    "        \"end_time\": datetime(2020, 11, 30)\n",
    "}\n",
    "bcm_model_2 = bcm_seir_age_strat(model_config)\n",
    "model_2 = model2(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm_model_2.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_params = {k:v.ppf(0.5) for k,v in bcm_model_2.priors.items() if \"_disp\" in k} #Mandatory if you tempt to calibrate your target dispersion\n",
    "\n",
    "res = bcm_model_2.run(bcm_model_2.parameters | disp_params).derived_outputs\n",
    "\n",
    "# res = model_2.get_outputs_df()\n",
    "Infec = [f\"IXage_{i}\" for i in range(0,65,5)] #Selecting the Infectious compartments\n",
    "#Summing over the infectious compartments \n",
    "total_cases_pred = pd.DataFrame(res[Infec].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_start_date = datetime(2020, 8, 1)\n",
    "analysis_end_date = datetime(2020, 11, 30)\n",
    "\n",
    "# plot = model_2.get_outputs_df()[\"IXage_60\"].plot()\n",
    "plot = pd.DataFrame(total_cases_pred).plot()\n",
    "plot.update_xaxes(range=(plot_start_date, analysis_end_date))\n",
    "plot.add_trace(go.Scatter(x=total_cases.index, y=total_cases[\"cases\"], mode='markers', name='total_cases'))\n",
    "#pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "#pivot_df[\"total_cases\"].plot.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing by optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nevergrad as ng\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# Import our convenience wrapper\n",
    "from estival.wrappers.nevergrad import optimize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TwoPointsDE is a good suggested default for some of our typical use cases\n",
    "opt_class = ng.optimizers.TwoPointsDE\n",
    "orunner = optimize_model(bcm_model_2, opt_class=opt_class)\n",
    "# Here we run the optimizer in a loop, inspecting the current best point at each iteration\n",
    "# Using the loss information at each step can provide the basis for stopping conditions\n",
    "\n",
    "# for i in range(8):\n",
    "    # Run the minimizer for a specified 'budget' (ie number of evaluations)\n",
    "rec = orunner.minimize(1000)\n",
    "    # Print the loss (objective function value) of the current recommended parameters\n",
    "# print(rec.loss)\n",
    "mle_params = rec.value[1]\n",
    "res_opt = bcm_model_2.run(mle_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_pred_opt = pd.DataFrame(res_opt.derived_outputs[Infec].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = total_cases[\"Aug 2020\":\"Nov 2020\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start_date = datetime(2020, 8, 1)\n",
    "analysis_end_date = datetime(2020, 11, 30)\n",
    "\n",
    "# plot = model_2.get_outputs_df()[\"IXage_60\"].plot()\n",
    "plot = pd.DataFrame(total_cases_pred_opt).plot()\n",
    "plot.update_xaxes(range=(plot_start_date, analysis_end_date))\n",
    "plot.add_trace(go.Scatter(x=D.index, y=D[\"cases\"], mode='markers', name='total_cases'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##____Uniform Initialisation for each chain_________\n",
    "chains = 4\n",
    "init_vals = []\n",
    "for c in range(chains):\n",
    "    temp = {param: np.random.uniform(0.0,1.0) for param in list(bcm_model_2.parameters.keys())[:-2]}\n",
    "    temp[\"incubation_period\"] = np.random.uniform(1.,15.) \n",
    "    temp[\"infectious_period\"] = np.random.uniform(1.,15.)\n",
    "    init_vals.append(temp)\n",
    "\n",
    "\n",
    "init_vals_nuts = {param: jnp.array(np.random.uniform(0.0,1.0, 4)) for param in list(bcm_model_2.parameters)[:-2]}\n",
    "init_vals_nuts[\"incubation_period\"] = jnp.array(np.random.uniform(1.,15.0, 4))\n",
    "init_vals_nuts[\"infectious_period\"] = jnp.array(np.random.uniform(1.,15.0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmodel_2():\n",
    "    unif_priors = list(bcm_model_2.parameters)[:-2]\n",
    "    sampled = {k:numpyro.sample(k, dist.Uniform(0.0,1.0)) for k in unif_priors}\n",
    "    sampled[\"seed\"] = numpyro.sample(\"seed\", dist.Uniform(1.0,1000))\n",
    "    #Adding the normal priors for the incubation and infectious periods\n",
    "\n",
    "    # sampled[\"incubation_period\"] = numpyro.sample(\"incubation_period\", dist.TruncatedNormal(7.3, 2.0, low=1., high=14.))\n",
    "    # sampled[\"infectious_period\"] = numpyro.sample(\"infectious_period\", dist.TruncatedNormal(5.4, 3.0, low=1., high=14.))\n",
    "    # Log-likelihood\n",
    "    disp_params = {k:v.ppf(0.5) for k,v in bcm_model_2.priors.items() if \"_disp\" in k}\n",
    "\n",
    "    log_likelihood = bcm_model_2.loglikelihood(**sampled | disp_params)\n",
    "\n",
    "    numpyro.factor(\"ll\",log_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a Single run for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samplers =  [pm.sample_smc,pm.Metropolis,pm.DEMetropolisZ,pm.DEMetropolis]\n",
    "Draws = [5000]*4\n",
    "# Init = [init_vals_4]*4\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for sampler, draws in zip(samplers, Draws):#, Init):\n",
    "    \n",
    "    results = cal.Single_analysis(sampler = sampler, \n",
    "            draws = draws,\n",
    "            chains=4,\n",
    "            cores = 4,\n",
    "            tune = 1000,\n",
    "            bcm_model = bcm_model_2,\n",
    "            # initial_params = init\n",
    "            )\n",
    "            \n",
    "    results_df = pd.concat([results_df,results])\n",
    "\n",
    "\n",
    "\n",
    "results_df = results_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trace = results_df[\"Trace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = Trace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabily the nuts will take a while to finish--We need to reduce the number of iterations and or warmup\n",
    "res_nuts = cal.Single_analysis(sampler = infer.NUTS, \n",
    "            draws = 1000,\n",
    "            tune = 10,\n",
    "            chains = 4,\n",
    "            cores=4,\n",
    "            bcm_model = bcm_model_2,\n",
    "            nmodel=nmodel_2,\n",
    "            initial_params = init_vals_nuts)\n",
    "\n",
    "results_df = pd.concat([results_df,res_nuts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting_test(sampler,idata, bcm, model):\n",
    "    from estival.sampling.tools import likelihood_extras_for_samples,likelihood_extras_for_idata\n",
    "    if sampler.__name__ in [\"DEMetropolis\", \"DEMetropolisZ\"]:\n",
    "        likelihood_df = likelihood_extras_for_idata(idata, bcm) #More faster\n",
    "    else :\n",
    "        likelihood_df = likelihood_extras_for_samples(idata.posterior, bcm)\n",
    "\n",
    "    ldf_sorted = likelihood_df.sort_values(by=\"logposterior\",ascending=False)\n",
    "\n",
    "    # Extract the parameters from the calibration samples\n",
    "    map_params = idata.posterior.to_dataframe().loc[ldf_sorted.index[0]].to_dict()\n",
    "    map_params['incubation_period']= 5.4\n",
    "    map_params['infectious_period'] = 7.3\n",
    "    print(map_params)\n",
    "    bcm.loglikelihood(**map_params), ldf_sorted.iloc[0][\"loglikelihood\"]\n",
    "    # Run the model with these parameters\n",
    "    model.run(map_params)\n",
    "    # ...and plot some results\n",
    "    return model.get_outputs_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res_smc = fitting_test(pm.sample_smc,idata, bcm_model_2,model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Infec = [f\"IXage_{i}\" for i in range(0,65,5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_pred_DEM = map_res_smc[Infec].sum(axis=1)\n",
    "total_cases_pred_SMC = map_res_smc[Infec].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases = total_cases[\"Aug 2020\":\"Nov 2020\"].iloc[::14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start_date = datetime(2020, 8, 1)\n",
    "analysis_end_date = datetime(2020, 11, 30)\n",
    "\n",
    "#plot= map_res[\"IXage_5\"].plot()\n",
    "plot = total_cases_pred_SMC.plot()\n",
    "plot.update_xaxes(range=(plot_start_date, analysis_end_date))\n",
    "# plot.add_trace(go.Scatter(x=df.loc[\"05_09\"].index, y=df.loc[\"05_09\"][\"cases\"], mode='markers', name='observed'))\n",
    "plot.add_trace(go.Scatter(x=total_cases.index, y=total_cases[\"cases\"], mode='markers', name='total_cases'))\n",
    "# plot.add_trace(go.Scatter(x=total_cases.index, y=total_cases_pred_DEM, name='DEM'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
