{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC CALIBRATION TECHNICS IN CONTEXT OF  INFECTIOUS DISEASE MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install multiprocess\n",
    "# %pip install --upgrade --force-reinstall multiprocess\n",
    "\n",
    "#Compatible with latest jax version  \n",
    "# %pip install summerepi2==1.3.6\n",
    "# %pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess as mp\n",
    "import platform\n",
    "\n",
    "# This is required for pymc parallel evaluation in notebooks \n",
    "# But has to be change while using a python script \n",
    "# Use this following instruction instead\n",
    "# if __name__ == \"__main__\":\n",
    "#     if platform.system() != \"Windows\":\n",
    "#         mp.set_start_method('spawn')\n",
    "    \n",
    "    # rest of your code body here inside the if __name__\n",
    "if platform.system() != \"Windows\":\n",
    "    \n",
    "    mp.set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Calibrate as cal #Runing the calibration process and gathering results\n",
    "from calibs_utilities import get_all_priors, get_targets, load_data\n",
    "from models.models import model1, model2, bcm_seir_age_strat, bcm_sir #All the models we design for the test\n",
    "from Calibrate import plot_comparison_bars\n",
    "\n",
    "# Combining tagets and prior with our summer2 model in a BayesianCompartmentalModel (bcm_model_1)\n",
    "from estival.model import BayesianCompartmentalModel\n",
    "from estival.sampling.tools import likelihood_extras_for_idata\n",
    "from estival.sampling.tools import likelihood_extras_for_samples\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "# We use estivals parallel tools to run the model evaluations\n",
    "from estival.utils.parallel import map_parallel\n",
    "\n",
    "import numpyro\n",
    "from numpyro import distributions as dist\n",
    "from numpyro import infer\n",
    "import arviz as az\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from plotly import graph_objects as go\n",
    "# import jax\n",
    "from jax import numpy as jnp\n",
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "# pd.options.plotting.backend = \"matplotlib\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 1: The basic SIR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and Configuration\n",
    "\n",
    "A mechanistic model (ODE-Based) model discribing Infectious Disease transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model1() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining  a Bayesian Compartmental Model\n",
    "#Targets and priors are already defined with the data \n",
    "#See models.py for the costumization\n",
    "bcm_model_1 = bcm_sir()\n",
    "# bcm_model_1 = BayesianCompartmentalModel(model_1, parameters, priors, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "output_labels = {\"index\": \"time\", \"value\": \"number infectious\"}\n",
    "\n",
    "model_1.run(bcm_model_1.parameters)\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"modelled\": model_1.get_outputs_df()[\"I\"],\n",
    "        \"observed\": bcm_model_1.targets[\"active_cases\"].data,\n",
    "    }\n",
    ")\n",
    "df.plot(kind=\"scatter\", labels=output_labels) #,figsize=(3,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##____Uniform Initialisation_________\n",
    "def init_uniform(num_chains, parameters):\n",
    "    init_vals = []\n",
    "    for c in range(num_chains):\n",
    "        init_vals.append({param: np.random.uniform(0.0,1.0) for param in parameters.keys()})\n",
    "    \n",
    "    return init_vals\n",
    "\n",
    "\n",
    "init_vals_nuts = {param: jnp.array(np.random.uniform(0.0,1.0, 4)) for param in bcm_model_1.parameters.keys()}\n",
    "\n",
    "init_vals_4 = init_uniform(4,bcm_model_1.parameters)\n",
    "init_vals_6 = init_uniform(6,bcm_model_1.parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "from numpyro import distributions as dist\n",
    "def nmodel():\n",
    "    sampled = {k:numpyro.sample(k, dist.Uniform(0.0,1.0)) for k in bcm_model_1.parameters}\n",
    "    ll = numpyro.factor(\"ll\", bcm_model_1.loglikelihood(**sampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "D = 2 # Dimension of the parameter's space\n",
    "samplers =  [infer.NUTS] + [pm.sample_smc] + [pm.Metropolis] + [pm.DEMetropolisZ] + [pm.DEMetropolis]*2\n",
    "Draws = [2000] + [2000] + [10000] + [8000]*3\n",
    "# Tunes = [0] + [100, 1000]*5\n",
    "Init = [init_vals_nuts] + [init_vals_4]*4 + [init_vals_6]\n",
    "Chains = [4]*5 + [6]\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for sampler, draws, chains, init in zip(samplers, Draws, Chains, Init):\n",
    "    # if sampler.__name__ == \"NUTS\":\n",
    "    #     init = init_vals_nuts\n",
    "    # else:\n",
    "    #     init = init_vals_4\n",
    "    results = cal.Single_analysis(sampler = sampler, \n",
    "            draws = draws,\n",
    "            chains=chains,\n",
    "            cores = chains,\n",
    "            tune = 1000,\n",
    "            bcm_model = bcm_model_1,\n",
    "            # n_iterations = 1,\n",
    "            nmodel=nmodel,\n",
    "            # n_jobs = 1,\n",
    "            initial_params = init\n",
    "\n",
    "    )\n",
    "            \n",
    "    results_df = pd.concat([results_df,results])\n",
    "\n",
    "\n",
    "\n",
    "results_df = results_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df\n",
    "results_df.style.set_caption(\"MCMC COMPARISON\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Storing results on a pickle file\n",
    "with open('./Results/Model_1/Simple_run_results_3.pkl', 'wb') as fp:\n",
    "    pickle.dump(results_df, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a pickle file\n",
    "with open('./Results/Model_1/Simple_run_results_3.pkl', 'rb') as fp:\n",
    "    res = pickle.load(fp)\n",
    "\n",
    "# res = pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trace = res.Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = Trace[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bar Ploting Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_comparison_Bars(results_df=res)\n",
    "plot_comparison_bars(res.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.sample_smc\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 2000,\n",
    "    tune = 1000,\n",
    "    chains=4,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    nmodel=nmodel,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    initial_params = init_vals_4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.DEMetropolis\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 8000,\n",
    "    tune = 1000,\n",
    "    chains=6,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    initial_params = init_vals_6\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.DEMetropolisZ\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 8000,\n",
    "    chains=4,\n",
    "    cores=4,\n",
    "    tune = 1000, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    initial_params = init_vals_4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.Metropolis\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    tune = 1000, \n",
    "    chains=4,\n",
    "    cores=4,\n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    initial_params = init_vals_4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = infer.NUTS\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 2000,\n",
    "    tune = 1000,\n",
    "    chains=4,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    nmodel=nmodel,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 2,\n",
    "    initial_params = init_vals_nuts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the results for later analysis\n",
    "\n",
    "with open('./Results/Model_1/Multi_run_results_3.pkl', 'wb') as fp:\n",
    "    pickle.dump(all_results, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing the 100 results\n",
    "\n",
    "We call the function group_summary from the calibrate modules. This will help to figure out the average performance\n",
    "of sampler over 100 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a pickle file\n",
    "with open('./Results/Model_1/Multi_run_results_3.pkl', 'rb') as fp:\n",
    "    multi_res = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(multi_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_mean, prcnt_succ = cal.group_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcnt_succ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using arviz for trace visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idata, Run, draws, tune in zip(res.Trace, res.Run, res.Draws, res.Tune):\n",
    "    subset = idata.sel(draw=slice(0, None), groups=\"posterior\")\n",
    "    print(\"Run = \",Run)\n",
    "    az.plot_trace(subset, figsize=(16,3.2*len(subset.posterior)),compact=False)#, lines=[(\"m\", {}, mtrue), (\"c\", {}, ctrue)]);\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting test\n",
    "\n",
    "Here we test if the model is well fitted to the data, we will use the results from the single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDATA = res[\"Trace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res = dict()\n",
    "for idata, run in zip(IDATA,res[\"Run\"]):\n",
    "    # print(idata)\n",
    "    map_res[run] = cal.fitting_test(idata, bcm_model_1, model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled = map_res[\"NUTS\\nDraws=2000\\nTune=1000\"][\"I\"]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"modelled\": modelled,\n",
    "        \"observed\": bcm_model_1.targets[\"active_cases\"].data,\n",
    "    }\n",
    ")\n",
    "df.plot(kind=\"scatter\", labels=output_labels, title=\"Model fitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the arviz extract method to obtain some samples, then convert to a DataFrame\n",
    "sample_idata = az.extract(idata, num_samples=4000)\n",
    "samples_df = sample_idata.to_dataframe().drop(columns=[\"chain\",\"draw\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function captures our bcm from the main namespace to pass into map_parallel\n",
    "# Using this idiom in closures/factory functions is typical\n",
    "def run_sample(idx_sample):\n",
    "    idx, params = idx_sample\n",
    "    return idx, bcm_model_1.run(params)\n",
    "\n",
    "# Run the samples through our BCM using the above function\n",
    "# map_parallel takes a function and an iterable as input\n",
    "\n",
    "# We use 4 workers here, default is cpu_count/2 (assumes hyperthreading)\n",
    "sample_res = map_parallel(run_sample, samples_df.iterrows(), n_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use xarray for this step; aside from computing things very quickly, it's useful\n",
    "# to persist the run results to netcdf/zarr etc\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res = cal.fitting_test(idata, bcm_model_1, model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res[\"I\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataArray out of our results, then assign coords for indexing\n",
    "xres = xr.DataArray(np.stack([r.derived_outputs for idx, r in sample_res]), \n",
    "                    dims=[\"sample\",\"time\",\"variable\"])\n",
    "xres = xres.assign_coords(sample=sample_idata.coords[\"sample\"], \n",
    "                          time=map_res.index, variable=pd.DataFrame(map_res[\"I\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some quantiles to calculate\n",
    "quantiles = (0.5,0.75,0.95)\n",
    "\n",
    "# Generate a new DataArray containing the quantiles\n",
    "xquantiles = xres.quantile(quantiles,dim=[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract these values to a pandas DataFrame for ease of plotting\n",
    "\n",
    "uncertainty_df = xquantiles.to_dataframe(name=\"value\").reset_index().set_index(\"time\").pivot(columns=(\"variable\",\"quantile\"))[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"active_cases\"\n",
    "pd.options.plotting.backend = \"matplotlib\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "\n",
    "fig = uncertainty_df[\"I\"].plot.area(title=variable,alpha=0.7)\n",
    "pd.Series(map_res[\"I\"]).plot(label = \"modelled\",style='--')\n",
    "bcm_model_1.targets[variable].data.plot(label = \"observed\",style='.',color=\"black\", ms=5, alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the posterior likelihood landscape analysis using ELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pflacco\n",
    "from pflacco.classical_ela_features import *\n",
    "from pflacco.local_optima_network_features import compute_local_optima_network, calculate_lon_features\n",
    "#__To___create_a_initial____sample\n",
    "from pflacco.sampling import create_initial_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 2: The SEIR age-stratified model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for fitting\n",
    "Here we will define a target for each age category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = pd.read_csv(\"./data/new_cases_England_2020.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df.date)\n",
    "df.set_index([\"age\",\"date\"], inplace=True)\n",
    "# df['date'] = pd.to_datetime(df['date'].str.split(' - ').str[0])\n",
    "# df.index=dfdate\n",
    "# targets_data = df.drop(columns='date')\n",
    "#pivot_df = df.pivot(index='date', columns='incidence', values='incidence')\n",
    "#pivot_df[\"total_cases\"]=pivot_df.sum(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_strat = [f\"{i}\" for i in range(0,65,5)]\n",
    "parameters = {\n",
    "    'age_transmission_rate_'+ str(age) : 0.25 for age in age_strat\n",
    "        }\n",
    "parameters['incubation_period']= 6\n",
    "parameters['infectious_period'] = 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages_labels = [f\"{i:02}_{i+4:02}\" for i in range(0,60, 5)] + [\"60+\"]\n",
    "targets_data = dict()\n",
    "for age in ages_labels:\n",
    "    targets_data[age] = df.loc[age]\n",
    "    # plt.plot(cases_per_age[age])\n",
    "# plt.show()\n",
    "# targets_data = pd.concat(targets_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat(targets_data)\n",
    "d = d.groupby(\"date\").sum()\n",
    "total_cases = d.rolling(14).mean().iloc[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm_model_2 = bcm_seir_age_strat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = targets_data[\"00_04\"].rolling(14).mean()[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = bcm_model_2.targets\n",
    "D = pd.DataFrame(T[\"incX0\"].data)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.run(parameters)\n",
    "\n",
    "res = model_2.get_outputs_df()\n",
    "Infec = [f\"IXage_{i}\" for i in range(0,65,5)]\n",
    "total_cases_pred = res[Infec].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_start_date = datetime(2020, 8, 1)\n",
    "analysis_end_date = datetime(2020, 11, 30)\n",
    "\n",
    "# plot = model_2.get_outputs_df()[\"IXage_60\"].plot()\n",
    "plot = pd.DataFrame(total_cases_pred).plot()\n",
    "plot.update_xaxes(range=(plot_start_date, analysis_end_date))\n",
    "plot.add_trace(go.Scatter(x=total_cases.index, y=total_cases[\"cases\"], mode='markers', name='total_cases'))\n",
    "#pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "#pivot_df[\"total_cases\"].plot.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining  a Bayesian Compartmental Model\n",
    "\n",
    "bcm_model_2 = BayesianCompartmentalModel(model_2, parameters, priors,targets)\n",
    "# T = bcm_model_2.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##____Uniform Initialisation for each chain_________\n",
    "chains = 4\n",
    "init_vals = []\n",
    "for c in range(chains):\n",
    "    temp = {param: np.random.uniform(0.0,1.0) for param in list(parameters.keys())[:-2]}\n",
    "    temp[\"incubation_period\"] = np.random.uniform(1.,15.) \n",
    "    temp[\"infectious_period\"] = np.random.uniform(1.,15.)\n",
    "    init_vals.append(temp)\n",
    "\n",
    "\n",
    "init_vals_nuts = {param: jnp.array(np.random.uniform(0.0,1.0, 4)) for param in list(bcm_model_2.parameters)[:-2]}\n",
    "init_vals_nuts[\"incubation_period\"] = jnp.array(np.random.uniform(1.,15.0, 4))\n",
    "init_vals_nuts[\"infectious_period\"] = jnp.array(np.random.uniform(1.,15.0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmodel_2():\n",
    "    # import numpyro.distributions.truncated as\n",
    "    unif_priors = list(bcm_model_2.parameters)[:-2]\n",
    "    sampled = {k:numpyro.sample(k, dist.Uniform(0.0,1.0)) for k in unif_priors}\n",
    "    #Adding the normal priors for the incubation and infectious periods\n",
    "    sampled[\"incubation_period\"] = numpyro.sample(\"incubation_period\", dist.TruncatedNormal(7.3, 2.0, low=1., high=15.))\n",
    "    sampled[\"infectious_period\"] = numpyro.sample(\"infectious_period\", dist.TruncatedNormal(5.4, 3.0, low=1., high=15.))\n",
    "\n",
    "    #Definir les normal priors\n",
    "    ll = numpyro.factor(\"ll\", bcm_model_2.loglikelihood(**sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cal.Single_analysis(sampler = pm.DEMetropolisZ, \n",
    "            draws = 100000,\n",
    "            tune = 5000,\n",
    "            chains = 4,\n",
    "            cores=4,\n",
    "            bcm_model = bcm_model_2,\n",
    "            # n_iterations = 1,\n",
    "            # n_jobs = 1,\n",
    "            nmodel=nmodel_2,\n",
    "            initial_params = init_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = res[\"Trace\"]\n",
    "idata = idata[0]\n",
    "burn_in = 50000\n",
    "subset = idata.sel(draw=slice(burn_in, None), groups=\"posterior\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(subset, figsize=(12,2.5*len(idata.posterior)),compact=False, legend=True)\n",
    "plt.tight_layout(pad = 0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res = fitting_test(subset, bcm_model_2,model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_pred = map_res()[Infec].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_start_date = datetime(2019, 12, 1)\n",
    "# analysis_end_date = datetime(2020, 3, 11)\n",
    "\n",
    "plot = total_cases_pred.plot()\n",
    "plot.update_xaxes(range=(plot_start_date, analysis_end_date))\n",
    "plot.add_trace(go.Scatter(x=total_cases.index, y=total_cases[\"cases\"], mode='markers', name='total_cases'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"incidence\"\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pd.DataFrame(map_res.derived_outputs[\"incidence\"]).plot(title = f\"{variable} (MLE)\")\n",
    "pd.DataFrame(bcm_model_2.targets[variable].data).plot(style='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
