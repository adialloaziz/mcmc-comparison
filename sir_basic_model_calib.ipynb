{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC CALIBRATION TECHNICS FOR DETERMINISTIC ODE-BASED INFECTIOUS DISEASE MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess as mp\n",
    "import platform\n",
    "if platform.system() != \"Windows\":\n",
    "    \n",
    "    mp.set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Calibrate as cal #Runing the calibration process and gathering results\n",
    "from calibs_utilities import get_all_priors, get_targets, load_data\n",
    "from models.models import model1, model2, bcm_seir_age_strat, bcm_sir #All the models we design for the test\n",
    "from Calibrate import plot_comparison_bars\n",
    "\n",
    "# Combining tagets and prior with our summer2 model in a BayesianCompartmentalModel (bcm_model_1)\n",
    "from estival.model import BayesianCompartmentalModel\n",
    "from estival.sampling.tools import likelihood_extras_for_idata\n",
    "from estival.sampling.tools import likelihood_extras_for_samples\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "# We use estivals parallel tools to run the model evaluations\n",
    "from estival.utils.parallel import map_parallel\n",
    "\n",
    "import numpyro\n",
    "from numpyro import distributions as dist\n",
    "from numpyro import infer\n",
    "import arviz as az\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from plotly import graph_objects as go\n",
    "# import jax\n",
    "from jax import numpy as jnp\n",
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "# pd.options.plotting.backend = \"matplotlib\"\n",
    "import pytensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 1: The basic SIR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and Configuration\n",
    "\n",
    "A mechanistic model (ODE-Based) model discribing Infectious Disease transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model1() #Only the SIR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining  a Bayesian Compartmental Model\n",
    "#Targets and priors are already defined with the data \n",
    "#See models.py for the models costumization\n",
    "bcm_model_1 = bcm_sir() #Directly by the function bcm sir\n",
    "\n",
    "#Or using the following by combining the SIR model with the Bayesian Compartmental\n",
    "# bcm_model_1 = BayesianCompartmentalModel(model_1, parameters, priors, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial run \n",
    "\n",
    "Here you can see a test of the SIR model ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "output_labels = {\"index\": \"time\", \"value\": \"number infectious\"}\n",
    "\n",
    "model_1.run(bcm_model_1.parameters) #Runing the model with default parameters\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        # \"modelled\": model_1.get_outputs_df()[\"I\"],\n",
    "        \"observed\": bcm_model_1.targets[\"active_cases\"].data,\n",
    "    }\n",
    ")\n",
    "df.plot(kind=\"scatter\", labels=output_labels) #,figsize=(3,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling \n",
    "\n",
    "In order to do an MCMC sampling you can use an explicite initialisation process or let the algorithm choose by default.\n",
    "\n",
    "Here we choose a uniform sample from the parameter range. Each chain has its own starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##____Uniform Initialisation_________\n",
    "def init_uniform(num_chains, parameters):\n",
    "    init_vals = []\n",
    "    for c in range(num_chains):\n",
    "        init_vals.append({param: np.random.uniform(0.0,1.0) for param in parameters.keys()})\n",
    "    \n",
    "    return init_vals\n",
    "\n",
    "\n",
    "init_vals_nuts = {param: jnp.array(np.random.uniform(0.0,1.0, 4)) for param in bcm_model_1.parameters.keys()}\n",
    "\n",
    "init_vals_4 = init_uniform(4,bcm_model_1.parameters)\n",
    "init_vals_6 = init_uniform(6,bcm_model_1.parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Numpyro model using our likelihood from the BaysianCompartmentalModel\n",
    "def nmodel():\n",
    "    sampled = {k:numpyro.sample(k, dist.Uniform(0.0,1.0)) for k in bcm_model_1.parameters}\n",
    "    ll = numpyro.factor(\"ll\", bcm_model_1.loglikelihood(**sampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Run\n",
    "\n",
    "In what following the model_1's parameters are calibrated by run simply each algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "D = 2 # Dimension of the parameter's space\n",
    "samplers = [pm.Metropolis] # [infer.NUTS] #+ [pm.sample_smc] + [pm.Metropolis] + [pm.DEMetropolisZ] + [pm.DEMetropolis]*2\n",
    "Draws = [8000] #[2000] #+ [2000] + [10000] + [8000]*3\n",
    "# Tunes = [0] + [100, 1000]*5\n",
    "Init =  [init_vals_4]#[init_vals_nuts] #+ [init_vals_4]*4 + [init_vals_6]\n",
    "Chains = [4]#*5 + [6]\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for sampler, draws, chains, init in zip(samplers, Draws, Chains, Init):\n",
    "    # if sampler.__name__ == \"NUTS\":\n",
    "    #     init = init_vals_nuts\n",
    "    # else:\n",
    "    #     init = init_vals_4\n",
    "    results = cal.Single_analysis(sampler = sampler, \n",
    "            draws = draws,\n",
    "            chains=chains,\n",
    "            cores = chains,\n",
    "            tune = 1000,\n",
    "            bcm_model = bcm_model_1,\n",
    "            # n_iterations = 1,\n",
    "            nmodel=nmodel,\n",
    "            # n_jobs = 1,\n",
    "            initial_params = init\n",
    "\n",
    "    )\n",
    "            \n",
    "    results_df = pd.concat([results_df,results])\n",
    "\n",
    "\n",
    "\n",
    "results_df = results_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df\n",
    "results_df.style.set_caption(\"MCMC COMPARISON\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Storing results into a pickled file\n",
    "\"\"\"\n",
    "with open('./Results/Model_1/Simple_run_results_3.pkl', 'wb') as fp:\n",
    "    pickle.dump(results_df, fp)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple runs\n",
    "Here we perform several runs (calibrating the same model) of each algorithm using the funciton multirun in the module named \"cal\".\n",
    "Note that we let the default aglorithm started points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.sample_smc\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    tune = 1000,\n",
    "    chains=4,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.DEMetropolisZ\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    chains=4,\n",
    "    cores=4,\n",
    "    tune = 1000, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.Metropolis\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    tune = 1000, \n",
    "    chains=4,\n",
    "    cores=4,\n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = infer.NUTS\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 10000,\n",
    "    tune = 1000,\n",
    "    chains=4,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    nmodel=nmodel,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pm.DEMetropolis\n",
    "all_results[sampler.__name__] = cal.multirun(\n",
    "    sampler, \n",
    "    draws = 1000,\n",
    "    tune = 1000,\n",
    "    chains=6,\n",
    "    cores=4, \n",
    "    bcm_model = bcm_model_1,\n",
    "    n_iterations = 100,\n",
    "    n_jobs = 3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"DEMetropolis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the results for later analysis\n",
    "\n",
    "# with open('./Results/Model_1/Multi_run_results_without_init_1.pkl', 'wb') as fp:\n",
    "#     pickle.dump(all_results, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing the 100 results\n",
    "\n",
    "We call the function group_summary from the calibrate module. This will help to figure out the average performance\n",
    "of sampler over 100 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a pickle file \n",
    "# with open('./Results/Model_1/Multi_run_results_3.pkl', 'rb') as fp:\n",
    "#     multi_res = pickle.load(fp) #It's a dict\n",
    "# df = pd.concat(multi_res) #converting to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here best results refers to the run with the min 'Max_rhat' for each sampler over the  runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = pd.DataFrame()\n",
    "for sampler in all_results.keys():\n",
    "    temp = all_results[sampler].round(3)\n",
    "    temp\n",
    "    best_rhat = temp.loc[[temp[\"Rhat_max\"].idxmin()]]\n",
    "    best_results = pd.concat([best_results,best_rhat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the Relative ESS\n",
    "best_results[\"Rel_Ess\"] = best_results['Min_Ess'].astype(float)/(best_results[\"Draws\"].astype(float)*best_results['Chains'].astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_mean, prcnt_succ = cal.group_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcnt_succ = prcnt_succ.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcnt_succ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using arviz for trace visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idata, sampler in zip(best_results.Trace, best_results.Sampler):\n",
    "    print(sampler)\n",
    "    az.plot_rank(idata,figsize=(9,4))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Ploting Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_comparison_Bars(results_df=res)\n",
    "best_results[\"Run\"] = best_results.Sampler + \"\\nDraws=\" + best_results.Draws.astype(str) + \"\\nTune=\" + best_results.Tune.astype(str) +\"\\nChains=\" + best_results.Chains.astype(str)\n",
    "plot_comparison_bars(best_results.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting test\n",
    "\n",
    "Here we test if the model is well fitted to the data, we will use the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDATA = best_results[\"Trace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res = dict()\n",
    "for idata, sampler in zip(IDATA,best_results[\"Sampler\"]):\n",
    "    map_res[sampler] = cal.fitting_test(idata, bcm_model_1, model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "\n",
    "NUTS = map_res[\"NUTS\"][\"I\"]\n",
    "SMC = map_res[\"sample_smc\"][\"I\"]\n",
    "DEM = map_res[\"DEMetropolis\"][\"I\"]\n",
    "MH = map_res[\"Metropolis\"][\"I\"]\n",
    "DEMZ = map_res[\"DEMetropolisZ\"][\"I\"]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {   \n",
    "        \"MH\": MH,\n",
    "        \"NUTS\": NUTS,\n",
    "        \"SMC\": SMC,\n",
    "        \"DEM\": DEM,\n",
    "        \"DEMZ\": DEMZ,\n",
    "        \"observed\": bcm_model_1.targets[\"active_cases\"].data,\n",
    "    }\n",
    ")\n",
    "df.plot(kind=\"scatter\", labels=output_labels, title=\"Model fitting\")#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty sampling\n",
    "\n",
    "Will be discarded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function captures our bcm from the main namespace to pass into map_parallel\n",
    "# Using this idiom in closures/factory functions is typical\n",
    "def run_sample(idx_sample):\n",
    "    idx, params = idx_sample\n",
    "    return idx, bcm_model_1.run(params)\n",
    "\n",
    "# Run the samples through our BCM using the above function\n",
    "# map_parallel takes a function and an iterable as input\n",
    "\n",
    "# We use 4 workers here, default is cpu_count/2 (assumes hyperthreading)\n",
    "sample_res = dict()\n",
    "for idata,sampler in zip(IDATA,best_results[\"Sampler\"]):\n",
    "    sample_idata = az.extract(idata, num_samples=4000)\n",
    "    samples_df = sample_idata.to_dataframe().drop(columns=[\"chain\",\"draw\"])\n",
    "    sample_res[sampler] = map_parallel(run_sample, samples_df.iterrows(), n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use xarray for this step; aside from computing things very quickly, it's useful\n",
    "# to persist the run results to netcdf/zarr etc\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataArray out of our results, then assign coords for indexing\n",
    "xres = xr.DataArray(np.stack([r.derived_outputs for idx, r in sample_res[\"NUTS\"]]), \n",
    "                    dims=[\"sample\",\"time\",\"variable\"])\n",
    "xres = xres.assign_coords(sample=sample_idata.coords[\"sample\"], \n",
    "                          time=map_res[\"NUTS\"].index, variable=pd.DataFrame(map_res[\"NUTS\"][\"I\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some quantiles to calculate\n",
    "quantiles = (0.5,0.75,0.95)\n",
    "\n",
    "# Generate a new DataArray containing the quantiles\n",
    "xquantiles = xres.quantile(quantiles,dim=[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract these values to a pandas DataFrame for ease of plotting\n",
    "\n",
    "uncertainty_df = xquantiles.to_dataframe(name=\"value\").reset_index().set_index(\"time\").pivot(columns=(\"variable\",\"quantile\"))[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"active_cases\"\n",
    "pd.options.plotting.backend = \"matplotlib\" #To allow plotly graphic. Swich to \"matplotlib\" if facing some troubles while ploting\n",
    "\n",
    "fig = uncertainty_df[\"I\"].plot.area(title=variable,alpha=0.7)\n",
    "pd.Series(map_res[\"NUTS\"][\"I\"]).plot(label = \"modelled\",style='--')\n",
    "bcm_model_1.targets[variable].data.plot(label = \"observed\",style='.',color=\"black\", ms=5, alpha=0.8)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
